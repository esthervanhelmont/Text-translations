{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Text Translation and Sentiment Analysis using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Project Overview:\n",
    "\n",
    "The objective of this project is to analyze the sentiment of movie reviews in three different languages - English, French, and Spanish. We have been given 30 movies, 10 in each language, along with their reviews and synopses in separate CSV files named `movie_reviews_eng.csv`, `movie_reviews_fr.csv`, and `movie_reviews_sp.csv`.\n",
    "\n",
    "- The first step of this project is to convert the French and Spanish reviews and synopses into English. This will allow us to analyze the sentiment of all reviews in the same language. We will be using pre-trained transformers from HuggingFace to achieve this task.\n",
    "\n",
    "- Once the translations are complete, we will create a single dataframe that contains all the movies along with their reviews, synopses, and year of release in all three languages. This dataframe will be used to perform sentiment analysis on the reviews of each movie.\n",
    "\n",
    "- Finally, we will use pretrained transformers from HuggingFace to analyze the sentiment of each review. The sentiment analysis results will be added to the dataframe. The final dataframe will have 30 rows\n",
    "\n",
    "\n",
    "The output of the project will be a CSV file with a header row that includes column names such as **Title**, **Year**, **Synopsis**, **Review**, **Review Sentiment**, and **Original Language**. The **Original Language** column will indicate the language of the review and synopsis (*en/fr/sp*) before translation. The dataframe will consist of 30 rows, with each row corresponding to a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (4.56.2)\n",
      "Requirement already satisfied: sentencepiece in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from requests->transformers) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"K:\\Python\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"K:\\Python\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"K:\\Python\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tayfu\\AppData\\Local\\Temp\\ipykernel_26816\\3088334331.py\", line 3, in <module>\n",
      "    from transformers import MarianMTModel, MarianTokenizer\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\transformers\\__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\transformers\\dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\transformers\\utils\\__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\transformers\\utils\\auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py\", line 51, in <module>\n",
      "    import torch  # noqa: F401\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get data from `.csv` files and then preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the three movie review CSV files from the local 'data' folder,\n",
    "    standardizes column names, adds 'Original Language', and returns\n",
    "    a single combined dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # English\n",
    "    df_eng = pd.read_csv(\"data/movie_reviews_eng.csv\")\n",
    "    df_eng = df_eng.rename(columns={\n",
    "        df_eng.columns[0]: \"Title\",\n",
    "        df_eng.columns[1]: \"Year\",\n",
    "        df_eng.columns[2]: \"Synopsis\",\n",
    "        df_eng.columns[3]: \"Review\"\n",
    "    })\n",
    "    df_eng[\"Original Language\"] = \"en\"\n",
    "\n",
    "    # French\n",
    "    df_fr = pd.read_csv(\"data/movie_reviews_fr.csv\")\n",
    "    df_fr = df_fr.rename(columns={\n",
    "        df_fr.columns[0]: \"Title\",\n",
    "        df_fr.columns[1]: \"Year\",\n",
    "        df_fr.columns[2]: \"Synopsis\",\n",
    "        df_fr.columns[3]: \"Review\"\n",
    "    })\n",
    "    df_fr[\"Original Language\"] = \"fr\"\n",
    "\n",
    "    # Spanish\n",
    "    df_sp = pd.read_csv(\"data/movie_reviews_sp.csv\")\n",
    "    df_sp = df_sp.rename(columns={\n",
    "        df_sp.columns[0]: \"Title\",\n",
    "        df_sp.columns[1]: \"Year\",\n",
    "        df_sp.columns[2]: \"Synopsis\",\n",
    "        df_sp.columns[3]: \"Review\"\n",
    "    })\n",
    "    df_sp[\"Original Language\"] = \"sp\"\n",
    "\n",
    "    # Combine all into one dataframe\n",
    "    df = pd.concat([df_eng, df_fr, df_sp], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "df = preprocess_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Review</th>\n",
       "      <th>Original Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Les Visiteurs en Amérique</td>\n",
       "      <td>2000</td>\n",
       "      <td>Dans cette suite de la comédie française Les V...</td>\n",
       "      <td>\"Le film est une perte de temps totale. Les bl...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>Batman (Christian Bale) teams up with District...</td>\n",
       "      <td>\"The Dark Knight is a thrilling and intense su...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>Dom Cobb (Leonardo DiCaprio) is a skilled thie...</td>\n",
       "      <td>\"Inception is a mind-bending and visually stun...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Torrente: El brazo tonto de la ley</td>\n",
       "      <td>1998</td>\n",
       "      <td>En esta comedia española, un policía corrupto ...</td>\n",
       "      <td>\"Torrente es una película vulgar y ofensiva qu...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>La Casa de Papel</td>\n",
       "      <td>(2017-2021)</td>\n",
       "      <td>Esta serie de televisión española sigue a un g...</td>\n",
       "      <td>\"La Casa de Papel es una serie emocionante y a...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Le Fabuleux Destin d'Amélie Poulain</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cette comédie romantique raconte l'histoire d'...</td>\n",
       "      <td>\"Le Fabuleux Destin d'Amélie Poulain est un fi...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Les Choristes</td>\n",
       "      <td>2004</td>\n",
       "      <td>Ce film raconte l'histoire d'un professeur de ...</td>\n",
       "      <td>\"Les Choristes est un film magnifique qui vous...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>El Bar</td>\n",
       "      <td>2017</td>\n",
       "      <td>Un grupo de personas quedan atrapadas en un ba...</td>\n",
       "      <td>\"El Bar es una película ridícula y sin sentido...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Toc Toc</td>\n",
       "      <td>2017</td>\n",
       "      <td>En esta comedia española, un grupo de personas...</td>\n",
       "      <td>\"Toc Toc es una película aburrida y poco origi...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>La La Land</td>\n",
       "      <td>2016</td>\n",
       "      <td>Cette comédie musicale raconte l'histoire d'un...</td>\n",
       "      <td>\"La La Land est un film absolument magnifique ...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title         Year  \\\n",
       "18            Les Visiteurs en Amérique         2000   \n",
       "1                      The Dark Knight          2008   \n",
       "4                             Inception         2010   \n",
       "28   Torrente: El brazo tonto de la ley         1998   \n",
       "21                     La Casa de Papel  (2017-2021)   \n",
       "14  Le Fabuleux Destin d'Amélie Poulain         2001   \n",
       "13                        Les Choristes         2004   \n",
       "27                               El Bar         2017   \n",
       "26                              Toc Toc         2017   \n",
       "10                           La La Land         2016   \n",
       "\n",
       "                                             Synopsis  \\\n",
       "18  Dans cette suite de la comédie française Les V...   \n",
       "1   Batman (Christian Bale) teams up with District...   \n",
       "4   Dom Cobb (Leonardo DiCaprio) is a skilled thie...   \n",
       "28  En esta comedia española, un policía corrupto ...   \n",
       "21  Esta serie de televisión española sigue a un g...   \n",
       "14  Cette comédie romantique raconte l'histoire d'...   \n",
       "13  Ce film raconte l'histoire d'un professeur de ...   \n",
       "27  Un grupo de personas quedan atrapadas en un ba...   \n",
       "26  En esta comedia española, un grupo de personas...   \n",
       "10  Cette comédie musicale raconte l'histoire d'un...   \n",
       "\n",
       "                                               Review Original Language  \n",
       "18  \"Le film est une perte de temps totale. Les bl...                fr  \n",
       "1   \"The Dark Knight is a thrilling and intense su...                en  \n",
       "4   \"Inception is a mind-bending and visually stun...                en  \n",
       "28  \"Torrente es una película vulgar y ofensiva qu...                sp  \n",
       "21  \"La Casa de Papel es una serie emocionante y a...                sp  \n",
       "14  \"Le Fabuleux Destin d'Amélie Poulain est un fi...                fr  \n",
       "13  \"Les Choristes est un film magnifique qui vous...                fr  \n",
       "27  \"El Bar es una película ridícula y sin sentido...                sp  \n",
       "26  \"Toc Toc es una película aburrida y poco origi...                sp  \n",
       "10  \"La La Land est un film absolument magnifique ...                fr  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Text translation\n",
    "\n",
    "Translate the **Review** and **Synopsis** column values to English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We load two translation models (French→English and Spanish→English) and create a simple function called `translate()`.  \n",
    "\n",
    "This function takes a text, sends it through the model, and returns the English translation.  \n",
    "\n",
    "We will use it later to translate all movie reviews and synopses into English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch>=2.6.0\n",
      "  Downloading torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from torch>=2.6.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from torch>=2.6.0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from torch>=2.6.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from torch>=2.6.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from torch>=2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from torch>=2.6.0) (2025.10.0)\n",
      "Collecting setuptools (from torch>=2.6.0)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (from jinja2->torch>=2.6.0) (2.1.5)\n",
      "Downloading torch-2.9.1-cp312-cp312-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 3.4/110.9 MB 18.3 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 16.5/110.9 MB 43.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 31.7/110.9 MB 53.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 41.2/110.9 MB 51.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 42.7/110.9 MB 41.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 46.1/110.9 MB 37.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 48.2/110.9 MB 33.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 55.8/110.9 MB 33.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 63.2/110.9 MB 33.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 77.6/110.9 MB 37.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 91.2/110.9 MB 39.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 103.8/110.9 MB 41.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 42.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 40.2 MB/s  0:00:02\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: setuptools, torch\n",
      "\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "  Attempting uninstall: torch\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "    Found existing installation: torch 2.2.2+cpu\n",
      "   ---------------------------------------- 0/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "    Uninstalling torch-2.2.2+cpu:\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "      Successfully uninstalled torch-2.2.2+cpu\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torch]\n",
      "   ---------------------------------------- 2/2 [torch]\n",
      "\n",
      "Successfully installed setuptools-80.9.0 torch-2.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'G:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: safetensors in g:\\dev\\esther\\text translations\\.venv\\lib\\site-packages (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tayfu\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-fr-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tayfu\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-es-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# load translation models and tokenizers\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# TODO 2: Update the code below\n",
    "fr_en_model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "es_en_model_name = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "\n",
    "fr_en_tokenizer = MarianTokenizer.from_pretrained(fr_en_model_name)\n",
    "fr_en_model = MarianMTModel.from_pretrained(fr_en_model_name)\n",
    "\n",
    "es_en_tokenizer = MarianTokenizer.from_pretrained(es_en_model_name)\n",
    "es_en_model = MarianMTModel.from_pretrained(es_en_model_name)\n",
    "\n",
    "\n",
    "# TODO 3: Complete the function below\n",
    "def translate(text: str, model, tokenizer) -> str:\n",
    "    \"\"\"\n",
    "    function to translate a text using a model and tokenizer\n",
    "    \"\"\"\n",
    "    # encode the text using the tokenizer\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # generate the translation using the model\n",
    "    outputs = model.generate(**inputs, max_length=512)\n",
    "\n",
    "    # decode the generated output and return the translated text\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a dataframe with movies in three languages:\n",
    "English, French, and Spanish.\n",
    "\n",
    "English reviews don’t need translation, but French and Spanish do.\n",
    "\n",
    "So in this code we:\n",
    "- Find all French reviews and translate them to English.\n",
    "- Find all French synopses and translate them to English.\n",
    "- Find all Spanish reviews and translate them to English.\n",
    "- Find all Spanish synopses and translate them to English.\n",
    "\n",
    "Put the translated text back into the dataframe, replacing the original French/Spanish text.\n",
    "\n",
    "After this step, all movies have their review and synopsis in English, no matter what the original language was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_data_ptr_allocated' from 'torch.distributed.utils' (g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\distributed\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# TODO 4: Update the code below\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# filter reviews in French and translate to English\u001b[39;00m\n\u001b[32m      4\u001b[39m fr_reviews = df.loc[df[\u001b[33m\"\u001b[39m\u001b[33mOriginal Language\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mReview\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m fr_reviews_en = \u001b[43mfr_reviews\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_en_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_en_tokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# filter synopsis in French and translate to English\u001b[39;00m\n\u001b[32m      8\u001b[39m fr_synopsis = df.loc[df[\u001b[33m\"\u001b[39m\u001b[33mOriginal Language\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSynopsis\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# TODO 4: Update the code below\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# filter reviews in French and translate to English\u001b[39;00m\n\u001b[32m      4\u001b[39m fr_reviews = df.loc[df[\u001b[33m\"\u001b[39m\u001b[33mOriginal Language\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mReview\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m fr_reviews_en = fr_reviews.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_en_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_en_tokenizer\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# filter synopsis in French and translate to English\u001b[39;00m\n\u001b[32m      8\u001b[39m fr_synopsis = df.loc[df[\u001b[33m\"\u001b[39m\u001b[33mOriginal Language\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSynopsis\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtranslate\u001b[39m\u001b[34m(text, model, tokenizer)\u001b[39m\n\u001b[32m     21\u001b[39m inputs = tokenizer(text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# generate the translation using the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# decode the generated output and return the translated text\u001b[39;00m\n\u001b[32m     27\u001b[39m decoded = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[39m, in \u001b[36mdecorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot decorate classes; it is ambiguous whether or not only the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mconstructor or all methods should have the context manager applied; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mindividually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.isgeneratorfunction(func):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrap_generator(ctx_factory, func)\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2287\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2285\u001b[39m \u001b[38;5;66;03m# 2. Set generation parameters if not already defined\u001b[39;00m\n\u001b[32m   2286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2287\u001b[39m     synced_gpus = (is_deepspeed_zero3_enabled() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mis_fsdp_managed_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mand\u001b[39;00m dist.get_world_size() > \u001b[32m1\u001b[39m\n\u001b[32m   2289\u001b[39m logits_processor = logits_processor \u001b[38;5;28;01mif\u001b[39;00m logits_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m LogitsProcessorList()\n\u001b[32m   2290\u001b[39m stopping_criteria = stopping_criteria \u001b[38;5;28;01mif\u001b[39;00m stopping_criteria \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m StoppingCriteriaList()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\transformers\\integrations\\fsdp.py:35\u001b[39m, in \u001b[36mis_fsdp_managed_module\u001b[39m\u001b[34m(module)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.distributed.is_available():\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfsdp\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, torch.distributed.fsdp.FullyShardedDataParallel) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m     38\u001b[39m     module, \u001b[33m\"\u001b[39m\u001b[33m_is_fsdp_managed_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     39\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\distributed\\fsdp\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_flat_param\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlatParameter \u001b[38;5;28;01mas\u001b[39;00m FlatParameter\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fully_shard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     CPUOffloadPolicy,\n\u001b[32m      4\u001b[39m     FSDPModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     UnshardHandle,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfully_sharded_data_parallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     BackwardPrefetch,\n\u001b[32m     13\u001b[39m     CPUOffload,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     StateDictType,\n\u001b[32m     28\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\distributed\\fsdp\\_flat_param.py:24\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfsdp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_common_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     _FSDPDeviceHandle,\n\u001b[32m     19\u001b[39m     _named_parameters_with_duplicates,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     HandleTrainingState,\n\u001b[32m     23\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     _alloc_storage,\n\u001b[32m     26\u001b[39m     _data_ptr_allocated,\n\u001b[32m     27\u001b[39m     _free_storage,\n\u001b[32m     28\u001b[39m     _p_assert,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ParameterMeta  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtesting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_pg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeProcessGroup\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_data_ptr_allocated' from 'torch.distributed.utils' (g:\\Dev\\Esther\\Text translations\\.venv\\Lib\\site-packages\\torch\\distributed\\utils.py)"
     ]
    }
   ],
   "source": [
    "# TODO 4: Update the code below\n",
    "\n",
    "# filter reviews in French and translate to English\n",
    "fr_reviews = df.loc[df[\"Original Language\"] == \"fr\", \"Review\"]\n",
    "fr_reviews_en = fr_reviews.apply(lambda x: translate(str(x), fr_en_model, fr_en_tokenizer))\n",
    "\n",
    "# filter synopsis in French and translate to English\n",
    "fr_synopsis = df.loc[df[\"Original Language\"] == \"fr\", \"Synopsis\"]\n",
    "fr_synopsis_en = fr_synopsis.apply(lambda x: translate(str(x), fr_en_model, fr_en_tokenizer))\n",
    "\n",
    "# filter reviews in Spanish and translate to English\n",
    "es_reviews = df.loc[df[\"Original Language\"] == \"sp\", \"Review\"]\n",
    "es_reviews_en = es_reviews.apply(lambda x: translate(str(x), es_en_model, es_en_tokenizer))\n",
    "\n",
    "# filter synopsis in Spanish and translate to English\n",
    "es_synopsis = df.loc[df[\"Original Language\"] == \"sp\", \"Synopsis\"]\n",
    "es_synopsis_en = es_synopsis.apply(lambda x: translate(str(x), es_en_model, es_en_tokenizer))\n",
    "\n",
    "# update dataframe with translated text (overwrite original Review and Synopsis)\n",
    "df.loc[df[\"Original Language\"] == \"fr\", \"Review\"] = fr_reviews_en\n",
    "df.loc[df[\"Original Language\"] == \"fr\", \"Synopsis\"] = fr_synopsis_en\n",
    "\n",
    "df.loc[df[\"Original Language\"] == \"sp\", \"Review\"] = es_reviews_en\n",
    "df.loc[df[\"Original Language\"] == \"sp\", \"Synopsis\"] = es_synopsis_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/movie_reviews_eng.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df.sample(\u001b[32m10\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mReads movie data from .csv files, map column names, add the \u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m'Original Language' column, and concatenate into one dataframe.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# English\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_eng = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/movie_reviews_eng.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df_eng = df_eng.rename(columns={\n\u001b[32m      9\u001b[39m     df_eng.columns[\u001b[32m0\u001b[39m]: \u001b[33m\"\u001b[39m\u001b[33mTitle\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     df_eng.columns[\u001b[32m1\u001b[39m]: \u001b[33m\"\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     df_eng.columns[\u001b[32m2\u001b[39m]: \u001b[33m\"\u001b[39m\u001b[33mSynopsis\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     df_eng.columns[\u001b[32m3\u001b[39m]: \u001b[33m\"\u001b[39m\u001b[33mReview\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m })\n\u001b[32m     14\u001b[39m df_eng[\u001b[33m\"\u001b[39m\u001b[33mOriginal Language\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/movie_reviews_eng.csv'"
     ]
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Use HuggingFace pretrained model for sentiment analysis of the reviews. Store the sentiment result **Positive** or **Negative** in a new column titled **Sentiment** in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to know whether each movie review is positive or negative.\n",
    "To do that, we use a ready-made AI model from HuggingFace.\n",
    "\n",
    "HuggingFace is like an “app store for AI models.”\n",
    "You can download models for translation, summarization, sentiment analysis, and more. All without building them yourself.\n",
    "\n",
    "In this part of the code:\n",
    "- We load a sentiment analysis model from HuggingFace.\n",
    "- This model already knows how to read text and decide if it sounds happy, angry, or negative.\n",
    "- We write a simple function called analyze_sentiment():\n",
    "- It takes a piece of text and sends it to the model\n",
    "- And the model tells us: POSITIVE or NEGATIVE\n",
    "\n",
    "So now, for every translated review, we can automatically check how the reviewer felt about the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO 5: Update the code below\n",
    "# load sentiment analysis model\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "\n",
    "\n",
    "# TODO 6: Complete the function below\n",
    "def analyze_sentiment(text, classifier):\n",
    "    \"\"\"\n",
    "    function to perform sentiment analysis on a text using a model\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    result = classifier(str(text))[0]     # returns {'label': 'POSITIVE', 'score': ...}\n",
    "    return result[\"label\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posive or negative label\n",
    "We apply the `analyze_sentiment()` function to every movie review in the dataframe.  \n",
    "\n",
    "For each review, the model returns either **POSITIVE** or **NEGATIVE**.  \n",
    "We store this result in a new column called **Review Sentiment**, so every movie now has a sentiment label based on its English review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO 7: Add code below for sentiment analysis\n",
    "# perform sentiment analysis on reviews and store results in new column\n",
    "\n",
    "df[\"Review Sentiment\"] = df[\"Review\"].apply(lambda x: analyze_sentiment(x, sentiment_classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export the results to a .csv file\n",
    "df.to_csv(\"reviews_with_sentiment.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
